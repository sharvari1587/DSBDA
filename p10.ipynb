{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Term Frequency and Inverse Document Frequency. Considering\n",
    "sentences of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term Frequency (TF) for each sentence:\n",
      "Sentence 1: {'natural': 0.08333333333333333, 'language': 0.08333333333333333, 'processing': 0.041666666666666664, '(': 0.041666666666666664, 'nlp': 0.041666666666666664, ')': 0.041666666666666664, 'field': 0.041666666666666664, 'artificial': 0.041666666666666664, 'intelligence': 0.041666666666666664, 'concerned': 0.041666666666666664, 'interaction': 0.041666666666666664, 'computers': 0.041666666666666664, 'humans': 0.041666666666666664, '.': 0.041666666666666664}\n",
      "Sentence 2: {'focuses': 0.07142857142857142, 'interaction': 0.07142857142857142, 'computers': 0.07142857142857142, 'humans': 0.07142857142857142, 'natural': 0.07142857142857142, 'language': 0.07142857142857142, 'processing': 0.07142857142857142, '.': 0.07142857142857142}\n",
      "Sentence 3: {'nlp': 0.05555555555555555, 'techniques': 0.05555555555555555, 'used': 0.05555555555555555, 'analyze': 0.05555555555555555, ',': 0.1111111111111111, 'understand': 0.05555555555555555, 'generate': 0.05555555555555555, 'human': 0.05555555555555555, 'language': 0.05555555555555555, 'valuable': 0.05555555555555555, 'way': 0.05555555555555555, '.': 0.05555555555555555}\n",
      "\n",
      "Inverse Document Frequency (IDF) for each term:\n",
      "Term 'understand': IDF = 1.0986\n",
      "Term 'techniques': IDF = 1.0986\n",
      "Term ')': IDF = 1.0986\n",
      "Term 'analyze': IDF = 1.0986\n",
      "Term 'computers': IDF = 0.4055\n",
      "Term 'intelligence': IDF = 1.0986\n",
      "Term ',': IDF = 1.0986\n",
      "Term 'way': IDF = 1.0986\n",
      "Term 'generate': IDF = 1.0986\n",
      "Term 'used': IDF = 1.0986\n",
      "Term 'focuses': IDF = 1.0986\n",
      "Term 'natural': IDF = 0.4055\n",
      "Term '.': IDF = 0.0000\n",
      "Term 'human': IDF = 1.0986\n",
      "Term 'artificial': IDF = 1.0986\n",
      "Term 'valuable': IDF = 1.0986\n",
      "Term 'interaction': IDF = 0.4055\n",
      "Term '(': IDF = 1.0986\n",
      "Term 'processing': IDF = 0.4055\n",
      "Term 'humans': IDF = 0.4055\n",
      "Term 'language': IDF = 0.0000\n",
      "Term 'concerned': IDF = 1.0986\n",
      "Term 'field': IDF = 1.0986\n",
      "Term 'nlp': IDF = 0.4055\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "# Sample document containing multiple sentences\n",
    "document = \"\"\" Natural language processing (NLP) is a field of artificial intelligence concerned with the interaction between computers and humans in natural language. It focuses on the interaction between computers and humans through natural language processing. NLP techniques are used to analyze, understand, and generate human language in a valuable way. \"\"\"\n",
    "\n",
    "# Tokenize the document into sentences\n",
    "sentences = sent_tokenize(document)\n",
    "\n",
    "# Tokenize each sentence into words and remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokens = [word_tokenize(sentence.lower()) for sentence in sentences]\n",
    "tokens_without_stopwords = [[word for word in words if word not in stop_words] for words in tokens]\n",
    "\n",
    "# Calculate Term Frequency (TF) for each sentence\n",
    "tf_sentences = [{term: count/len(sentence) for term, count in Counter(words).items()} for words, sentence in zip(tokens_without_stopwords, tokens)]\n",
    "\n",
    "# Calculate Inverse Document Frequency (IDF) for each term\n",
    "all_terms = set([term for words in tokens_without_stopwords for term in words])\n",
    "idf = {term: math.log(len(sentences) / sum([1 for words in tokens_without_stopwords if term in words])) for term in all_terms}\n",
    "\n",
    "# Print TF and IDF for each sentence and term\n",
    "print(\"Term Frequency (TF) for each sentence:\")\n",
    "for i, tf_sentence in enumerate(tf_sentences, 1):\n",
    "    print(f\"Sentence {i}: {tf_sentence}\")\n",
    "\n",
    "print(\"\\nInverse Document Frequency (IDF) for each term:\")\n",
    "for term, idf_value in idf.items():\n",
    "    print(f\"Term '{term}': IDF = {idf_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizes the document into sentences using NLTK's sent_tokenize function.\n",
    "Tokenizes each sentence into words, converts them to lowercase, and removes stop words.\n",
    "Calculates Term Frequency (TF) for each sentence by counting the frequency of each term and dividing it by the total number of terms in the sentence.\n",
    "Calculates Inverse Document Frequency (IDF) for each term by counting the number of documents containing each term and taking the logarithm of the ratio of the total number of documents to the number of documents containing the term.\n",
    "Prints the TF and IDF values for each sentence and term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "file input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term Frequency (TF) for each sentence:\n",
      "Sentence 1: {'natural': 0.08695652173913043, 'language': 0.08695652173913043, 'processing': 0.043478260869565216, '(': 0.043478260869565216, 'nlp': 0.043478260869565216, ')': 0.043478260869565216, 'field': 0.043478260869565216, 'artificial': 0.043478260869565216, 'intelligeconcerned': 0.043478260869565216, 'interaction': 0.043478260869565216, 'computers': 0.043478260869565216, 'humans': 0.043478260869565216, '.': 0.043478260869565216}\n",
      "Sentence 2: {'focuses': 0.07142857142857142, 'interaction': 0.07142857142857142, 'computers': 0.07142857142857142, 'humans': 0.07142857142857142, 'natural': 0.07142857142857142, 'language': 0.07142857142857142, 'processing': 0.07142857142857142, '.': 0.07142857142857142}\n",
      "Sentence 3: {'nlp': 0.05555555555555555, 'techniques': 0.05555555555555555, 'used': 0.05555555555555555, 'analyze': 0.05555555555555555, ',': 0.1111111111111111, 'understand': 0.05555555555555555, 'generate': 0.05555555555555555, 'human': 0.05555555555555555, 'language': 0.05555555555555555, 'valuable': 0.05555555555555555, 'way': 0.05555555555555555, '.': 0.05555555555555555}\n",
      "\n",
      "Inverse Document Frequency (IDF) for each term:\n",
      "Term 'understand': IDF = 1.0986\n",
      "Term 'techniques': IDF = 1.0986\n",
      "Term ')': IDF = 1.0986\n",
      "Term 'analyze': IDF = 1.0986\n",
      "Term 'computers': IDF = 0.4055\n",
      "Term ',': IDF = 1.0986\n",
      "Term 'way': IDF = 1.0986\n",
      "Term 'generate': IDF = 1.0986\n",
      "Term 'used': IDF = 1.0986\n",
      "Term 'focuses': IDF = 1.0986\n",
      "Term 'natural': IDF = 0.4055\n",
      "Term '.': IDF = 0.0000\n",
      "Term 'human': IDF = 1.0986\n",
      "Term 'artificial': IDF = 1.0986\n",
      "Term 'valuable': IDF = 1.0986\n",
      "Term 'interaction': IDF = 0.4055\n",
      "Term '(': IDF = 1.0986\n",
      "Term 'processing': IDF = 0.4055\n",
      "Term 'intelligeconcerned': IDF = 1.0986\n",
      "Term 'humans': IDF = 0.4055\n",
      "Term 'language': IDF = 0.0000\n",
      "Term 'field': IDF = 1.0986\n",
      "Term 'nlp': IDF = 0.4055\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "# Read document from file\n",
    "def read_document(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "# Define file path\n",
    "file_path = 'p10.txt'\n",
    "\n",
    "# Tokenize document into sentences\n",
    "document = read_document(file_path)\n",
    "sentences = sent_tokenize(document)\n",
    "\n",
    "# Tokenize sentences into words and remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokens = [word_tokenize(sentence.lower()) for sentence in sentences]\n",
    "tokens_without_stopwords = [[word for word in words if word not in stop_words] for words in tokens]\n",
    "\n",
    "# Calculate Term Frequency (TF) for each sentence\n",
    "tf_sentences = [{term: count/len(sentence) for term, count in Counter(words).items()} for words, sentence in zip(tokens_without_stopwords, tokens)]\n",
    "\n",
    "# Calculate Inverse Document Frequency (IDF) for each term\n",
    "all_terms = set([term for words in tokens_without_stopwords for term in words])\n",
    "idf = {term: math.log(len(sentences) / sum([1 for words in tokens_without_stopwords if term in words])) for term in all_terms}\n",
    "\n",
    "# Print TF and IDF for each sentence and term\n",
    "print(\"Term Frequency (TF) for each sentence:\")\n",
    "for i, tf_sentence in enumerate(tf_sentences, 1):\n",
    "    print(f\"Sentence {i}: {tf_sentence}\")\n",
    "\n",
    "print(\"\\nInverse Document Frequency (IDF) for each term:\")\n",
    "for term, idf_value in idf.items():\n",
    "    print(f\"Term '{term}': IDF = {idf_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Term Frequency (TF) and Inverse Document Frequency (IDF) are two important concepts in natural language processing (NLP) used for text analysis and information retrieval tasks.\n",
    "\n",
    "1. **Term Frequency (TF)**:\n",
    "   - Term Frequency measures the frequency of a term (word) in a document relative to the total number of terms in that document.\n",
    "   - It is calculated as the ratio of the number of times a term appears in a document to the total number of terms in the document.\n",
    "   - Mathematically, TF is calculated using the formula:\n",
    "     \\[ \\text{TF}(t, d) = \\frac{\\text{Number of times term \\( t \\) appears in document \\( d \\)}}{\\text{Total number of terms in document \\( d \\)}} \\]\n",
    "   - TF values are normalized to prevent bias towards longer documents.\n",
    "\n",
    "2. **Inverse Document Frequency (IDF)**:\n",
    "   - Inverse Document Frequency measures the rarity of a term across all documents in a corpus.\n",
    "   - It is calculated as the logarithm of the ratio of the total number of documents in the corpus to the number of documents containing the term, scaled to avoid division by zero.\n",
    "   - Mathematically, IDF is calculated using the formula:\n",
    "     \\[ \\text{IDF}(t, D) = \\log\\left( \\frac{\\text{Total number of documents in corpus \\( D \\)}}{\\text{Number of documents containing term \\( t \\) in corpus \\( D \\)}} \\right) \\]\n",
    "   - IDF values increase with the rarity of a term across documents.\n",
    "\n",
    "Once TF and IDF values are calculated, they are often combined to form TF-IDF (Term Frequency-Inverse Document Frequency), which is a weighting scheme used to evaluate the importance of a term in a document relative to a corpus.\n",
    "\n",
    "Here's how you can calculate TF and IDF for sentences in a document:\n",
    "\n",
    "1. Tokenize the sentences and count the frequency of each term (word) within each sentence to calculate TF.\n",
    "2. Count the number of documents containing each term to calculate IDF.\n",
    "3. Combine TF and IDF to calculate TF-IDF.\n",
    "\n",
    "If you need code examples for implementing TF and IDF calculations in Python, let me know!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
